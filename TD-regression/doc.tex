\documentclass[a4paper,francais]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}

\usepackage{subfig}
\usepackage{graphicx}
\graphicspath{{fig/}}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cancel}

\usepackage{hyperref}

\usepackage{cprotect} %verbatim in footnote

\usepackage[english,linesnumbered,ruled,vlined]{algorithm2e}

\newcommand{\cad}{c.-à-d.}
\newcommand{\Z}{{\ensuremath\mathbb{Z}}}
\newcommand{\N}{{\ensuremath\mathbb{N}}}
\newcommand{\R}{{\ensuremath\mathbb{R}}}
\newtheorem{Theorem}{Theorem}

%-------- enable or disable correction -----------------------------
\theoremstyle{definition}
\newtheorem{exercice}{Exercice}[section]
\newtheorem*{solution}{Solution}

\usepackage{comment}
%\excludecomment{solution}% commenter/décommenter pour afficher/effacer l'impression des solutions


\title{Régression et optimisation sans contrainte}
\author{Tristan Roussillon}
\date{fév. 2025}

\begin{document}

\maketitle

Dans un problème de \emph{régression}, on cherche un modèle permettant de prédire une variable quantitative, dite \emph{à expliquer}
à partir d'autres variables, dites \emph{explicatives}. Les paramètres du modèle sont déterminés à partir d'observations
des variables en résolvant un problème d'optimisation sans contrainte, plus précisément en minimisant la somme des carrés
des écarts entre les observations réelles et les prédictions. Dans ce TD, on va commencer par un exemple pédagogique à une dimension,
puis on verra comment résoudre un problème de régression linéaire et non-linéaire à l'aide d'un réseau de neurones.

\section{Exemple pédagogique : la moyenne}
\label{sec:moyenne}

\begin{exercice}
  \'Etant donné un ensemble de valeurs $\{x_i\}_{i = 1,\dots,n}$ ($n \geq 1$),
  nous considérons la minimisation de la fonction $f : \R \rightarrow \R$ telle que :
  \[ f(x) = \sum_{i=1}^n (x-x_i)^2. \] 
  
  \begin{enumerate}
  \item Développez la somme et montrez que nous avons un polynôme du second degré en $x$.
  \item Calculez les dérivées premières et secondes de $f$.
  \item Quelles parties du cours nous indique que $f$ est convexe,
    que la valeur de $x$ telle que $f'(x) = 0$ est un minimum global ?
  \item Montrer que le minimum global est la moyenne de l'ensemble de valeurs.
  \end{enumerate}
\end{exercice}

\begin{solution}
  \begin{enumerate}
  \item $f(x) = n x^2 - 2(\sum_ix_i)x + (\sum_ix_i^2)$.
    Le graphe de $f$ est une parabole, $f$ est donc convexe.  
  \item $f'(x) = 2n x - 2(\sum_ix_i)$. $f''(x) = 2n \geq 2$. 
  \item
    \begin{enumerate}
    \item Le Théorème de convexité dit que si $f$ est continûment différentiable (deux fois), 
      la proposition ``$f$ est convexe'' est équivalente à ``$\forall x$, le hessien $\nabla^2f(x)$
      est une matrice \emph{semi-définie positive}''. Dans notre cas, le hessien $\nabla^2f(x)$
      est une matrice \emph{semi-définie positive} revient à $f''(x) \geq 0$, ce qui est vrai.
    \item Le théorème d'optimalité globale dit que si $f$ est convexe et continûment différentiable
      $\forall x$, $x^\star$ est un minimum global ssi ${\nabla f}^T(x^\star) = 0$.
      Dans notre cas, la condition est $f'(x^\star) = 0$. 
    \end{enumerate}
  \item On résoud $f'(x^\star) = 0 \Leftrightarrow x^\star = \frac{1}{n}\sum_ix_i$.
  \end{enumerate}  
\end{solution}

\begin{exercice}  
  Sur la même fonction, nous considérons maintenant la méthode de la descente de gradient,
  dont l'équation d'évolution est :
  \[ x^{(k+1)} = x^{(k)} - \lambda f'(x^{(k)}), \]
  avec $x^{(0)}$ fixé à $0$ et $\lambda$ un paramètre libre, à choisir. 
  \begin{enumerate}
  \item Que se passe-t-il si $\lambda$ est fixé à
    \begin{enumerate}
    \item $\frac{1}{n}$ ?
    \item $\frac{1}{2n}$ ?
    \item $\frac{1}{4n}$ ?
    \end{enumerate}
  \item \`A quelle méthode vue en cours correspond le choix $\frac{1}{2n}$ ?
  \end{enumerate}
\end{exercice}

\begin{solution}
  Pour simplifier, on note : $\frac{1}{n}\sum_ix_i =: \bar{x}$.
  On réécrit l'équation d'évolution avec le lambda choisi. 
  \begin{enumerate}
  \item Avec $\lambda = \frac{1}{n}$,
    on a $x^{(k+1)} = - x^{(k)} + 2\bar{x}$. Et donc
    $x^0 = 0, x^1 = 2\bar{x}, x^2 = 0, x^3 = 2\bar{x}, \dots$.
    Non convergence. 
  \item Avec $\lambda = \frac{1}{2n}$,
    on a $x^{(k+1)} = \bar{x}$. Et donc
    $x^0 = 0, x^1 = \bar{x}$. Arrêt après une itération
    quelle que soit la valeur précédente $x^{(k)}$.
    On remarque que $\frac{1}{2n} = \frac{1}{f''(x)}$ :
    faire un tel choix revient à appliquer la méthode de Newton. 
  \item Avec $\lambda = \frac{1}{4n}$,
    on a $x^{(k+1)} = \frac{(x^{(k)} + \bar{x})}{2}$. Et donc
    $x^0 = 0, x^1 = \frac{1}{2}\bar{x}, x^2 = \frac{3}{4}\bar{x},
    x^3 = \frac{7}{8}\bar{x}, \dots$.
    Convergence vers $\bar{x}$. 
  \end{enumerate}
\end{solution}

\section{Problème de régression linéaire et non-linéaire}
\label{sec:regression}

\newcommand\mat[1]{\mathbf{#1}}

%% Dans cette section, nous adoptons les notations utilisées habituellement
%% dans le contexte des réseaux de neurones.

Nous avons $d$ variables explicatives représentées par un vecteur $\vec{x} \in \R^d$
et une variable à expliquer $y \in \R$.
Nous avons un \emph{ensemble d'apprentissage} composé de $n$ observations :
$\{(\vec{x}_i,y_i)\}_{i = 1,\dots, n}$.
Enfin, nous considérons un modèle \emph{linéaire}, de paramètres $\vec{w} \in \R^d$
et $b \in \R$, tel que :

\[ \forall i, \hat{y}_i = \vec{w} \cdot \vec{x}_i + b, 
\quad \text{ou matriciellement,} \quad
\mat{\hat{y}} = \mat{w} \cdot \mat{x} + \mat{b}. \]

Le vecteur $\vec{w} \in \R^d$ est appelé \emph{poids}
et le scalaire $b$, \emph{biais}. 
L'objectif est de déterminer, à partir de l'ensemble d'apprentissage,
les paramètres $\vec{w},b$ inconnus en cherchant à minimiser le carré des
écarts entre les $y_i$ observés réellement et les prédictions $\hat{y}_i$.

\begin{exercice}
  Expliquez comment on peut considérer de manière équivalente
  les variables $\vec{x}', \vec{w}' \in \R^{d+1}$ pour considérer
  plus simplement $\forall i, \hat{y}_i = \vec{w}' \cdot \vec{x}'_i.$
\end{exercice}

\begin{solution}
  On définit $\vec{x}' = (x_1, \dots, x_d, 1)$ et
  $\vec{w}' = (w_1, \dots, w_d, b)$. On a bien
  $\vec{w}'\cdot\vec{x}' = \vec{w}\cdot\vec{x} + b$,
  d'où des règles de décision équivalentes. 
\end{solution}

Par la suite, nous allons continuer à travailler dans $\R^{d+1}$,
mais en omettant les primes pour plus de clarté. 

\begin{exercice}
  Calculez le gradient de la fonction de perte
  \footnote{Pour vous aider :
  le gradient de $f(\vec{w}) = \vec{w}\cdot\vec{x}$ est $\nabla f(\vec{w}) = \vec{x}$
  et le gradient de $g(\vec{w}) = (\vec{w}\cdot\vec{x})^2$ est
  $\nabla g(\vec{w}) = 2(\vec{w}\cdot\vec{x})\vec{x}$} :
  \[ L(\vec{w}) := \sum_{i=1}^{n} (y_i - \hat{y}_i)
  = \sum_{i=1}^{n} (y_i - \vec{w}\cdot\vec{x}_i)^2, \]
  et déduisez-en une manière de la minimiser. 
\end{exercice}

\begin{solution}
  En développant, on a
  \[ L(\vec{w}) = \sum_{i=1}^{n} ( y_i^2 - 2\vec{w} \cdot \vec{x}_i + (\vec{w} \cdot \vec{x}_i)^2 ), \]
  D'où
  \[ \nabla L(\vec{w}) = \sum_{i=1}^{n} ( 2\vec{x}_i + 2(\vec{w} \cdot \vec{x}_i)\vec{x}_i ). \]
  Equation d'évolution :
  \[ \vec{w} = \vec{w} - \lambda \nabla L(\vec{w}). \]
\end{solution}

Bien sûr, si la variable à expliquer n'est en réalité pas reliée
linéairement aux variables explicatives, l'écart entre les observations
et les prédictions restera important et pour faire mieux, il
faudra opter pour un modèle plus complexe. Le \emph{Théorème
d'approximation universelle} dit qu'il existe un modèle par lequel
on peut approximer n'importe quelle fonction aussi bien qu'on veut !
Le modèle est paramétré par un entier $k \in \N$ déterminant la taille
de deux matrices de poids : $\mat{w}_1$ de taille $k \times (d+1)$ et
$\mat{w}_2$ de taille $1 \times k$ :
\[ \mat{\hat{y}} = \mat{w}_2 \cdot \sigma ( \mat{w}_1 \cdot \mat{x} ), \]
où $\sigma$ est une fonction d'activation non polynomiale appliquée
élément par élément (sigmoïde, ReLu, etc.). 

\begin{exercice}
  ~
  
  \begin{itemize}
  \item Dessinez les matrices $\mat{y},\mat{\hat{y}},\mat{w}_2, \mat{w}_1, \mat{x}$. 
  \item Ce modèle est un réseau de neurones. Dessinez son architecture.
    Combien y a-t-il de couches ? de neurones ?
  \item Savez-vous calculer le gradient de la fonction de perte correspondant à ce modèle ?
  \end{itemize}
\end{exercice}

\begin{exercice}
  Téléchargez le code fourni. Il utilise \verb!PyTorch! pour calculer le
  gradient de la fonction de perte par différentiation automatique. Assurez-vous
  de comprendre les instructions de la boucle d'apprentissage. Testez en faisant
  varier les données (linéairement ou non-linéairement dépendantes, bruitées ou non),
  le taux d'apprentissage, le nombre d'époques et le paramètre $k$.  
\end{exercice}

\end{document}


